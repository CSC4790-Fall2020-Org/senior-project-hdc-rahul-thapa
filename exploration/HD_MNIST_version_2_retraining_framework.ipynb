{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from mnist import MNIST\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import accuracy_score\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "import copy\n",
    "import pandas as pd\n",
    "from perturbations_MNIST import elastic_transform, brightness, noise, skew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle(X, y):\n",
    "    permutation = np.arange(X.shape[0])\n",
    "    np.random.shuffle(permutation)\n",
    "    return X[permutation], y[permutation]\n",
    "\n",
    "def load_dataset():\n",
    "    mndata = MNIST('./data/')\n",
    "    X_train, labels_train = map(np.array, mndata.load_training())\n",
    "    X_test, labels_test = map(np.array, mndata.load_testing())\n",
    "    return X_train, labels_train, X_test, labels_test\n",
    "\n",
    "def get_scene(img, proj):\n",
    "    return np.dot(img, proj.T)\n",
    "\n",
    "# Transform the image vectors into the hypervectors\n",
    "def get_scenes(images, proj):\n",
    "    return np.dot(images[:NUM_SAMPLES, :], proj.T)\n",
    "\n",
    "def classify(images, digit_vectors):\n",
    "    similarities = cosine_similarity(images, digit_vectors)\n",
    "    classifications = np.argmax(similarities, axis=1)\n",
    "    return classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HD_classifiers(seed, encoding=\"float\"):\n",
    "    # print(\"Generating random projection...\")\n",
    "    # proj = np.random.rand(D, IMG_LEN * IMG_LEN)\n",
    "    print(\"Seed: \", seed)\n",
    "    print(\"Encoding: \", encoding)\n",
    "    print(\"Generating random projection...\")\n",
    "    np.random.seed(seed)\n",
    "    proj = np.random.rand(D, IMG_LEN * IMG_LEN)\n",
    "    if encoding == \"bipolar\":\n",
    "        proj[proj==0] = -1\n",
    "    print(proj.shape)\n",
    "    print(\"Projecting images to higher dim space...\")\n",
    "    X_train_copy = get_scenes(X_train, proj)\n",
    "    \n",
    "    digit_vectors = np.zeros((10, D))\n",
    "    print(\"Dimension of digit vector: \", digit_vectors.shape)\n",
    "    \n",
    "    for i in range(NUM_SAMPLES):\n",
    "        digit_vectors[y_train[i]] += X_train_copy[i]\n",
    "    digit_vectors = np.array(digit_vectors)\n",
    "    \n",
    "    if encoding == \"bipolar\":\n",
    "        digit_vectors[digit_vectors > 0] = 1\n",
    "        digit_vectors[digit_vectors <= 0] = -1\n",
    "    \n",
    "    predictions = classify(X_train_copy, digit_vectors)\n",
    "    acc = accuracy_score(y_train[:X_train_copy.shape[0]], predictions)\n",
    "    print(\"Train accuracy: \", acc)\n",
    "    \n",
    "    X_test_copy = get_scenes(X_test, proj)\n",
    "    predictions = classify(X_test_copy, digit_vectors)\n",
    "    acc = accuracy_score(y_test[:X_test_copy.shape[0]], predictions)\n",
    "    print(\"Test accuracy: \", acc)\n",
    "        \n",
    "    return digit_vectors, proj, X_train_copy, X_test_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discrepancies(models):\n",
    "    results_train = []\n",
    "    results_test = []\n",
    "#     model_names = []\n",
    "#     for seed, model in zip(seeds, models):\n",
    "    for i in range(len(models)):\n",
    "#         np.random.seed(seed)\n",
    "#         model_names.append(f\"model_{seed}\")\n",
    "#         proj = np.random.rand(D, IMG_LEN * IMG_LEN)\n",
    "#         X_train_copy = get_scenes(X_train, proj)\n",
    "#         X_test_copy = get_scenes(X_test, proj)\n",
    "        \n",
    "        predictions_train = classify(X_train_projs[i], models[i])\n",
    "        acc_train = accuracy_score(y_train[:X_train_projs[i].shape[0]], predictions_train)\n",
    "        \n",
    "        predictions_test = classify(X_test_projs[i], models[i])\n",
    "        acc_test = accuracy_score(y_test[:X_test_projs[i].shape[0]], predictions_test)\n",
    "        \n",
    "        print(f\"Seed {seeds[i]} Train Accuracy: \", acc_train)\n",
    "        print(f\"Seed {seeds[i]} Test Accuracy: \", acc_test)\n",
    "        \n",
    "        results_train.append(predictions_train)\n",
    "        results_test.append(predictions_test)\n",
    "    \n",
    "    if len(models) == 2:\n",
    "        df_train = pd.DataFrame({f'model_{seeds[0]}': list(results_train[0]),\n",
    "                   f'model_{seeds[1]}': list(results_train[1]),\n",
    "                   'y': y_train})\n",
    "        df_test = pd.DataFrame({f'model_{seeds[0]}': list(results_test[0]),\n",
    "                   f'model_{seeds[1]}': list(results_test[1]),\n",
    "                   'y': y_test})\n",
    "        df_discrepencies_train = df_train[(df_train[f\"model_{seeds[0]}\"] != df_train[f\"model_{seeds[1]}\"])]\n",
    "        df_discrepencies_test = df_test[(df_test[f\"model_{seeds[0]}\"] != df_test[f\"model_{seeds[1]}\"])]\n",
    "    elif len(models) == 3:\n",
    "        df_train = pd.DataFrame({f'model_{seeds[0]}': list(results_train[0]),\n",
    "                   f'model_{seeds[1]}': list(results_train[1]),\n",
    "                   f'model_{seeds[2]}': list(results_train[2]),\n",
    "                   'y': y_train})\n",
    "        df_test = pd.DataFrame({f'model_{seeds[0]}': list(results_test[0]),\n",
    "                   f'model_{seeds[1]}': list(results_test[1]),\n",
    "                   f'model_{seeds[2]}': list(results_test[2]),\n",
    "                   'y': y_test})\n",
    "        df_discrepencies_train = df_train[(df_train[f\"model_{seeds[0]}\"] != df_train[f\"model_{seeds[1]}\"]) | (df_train[f\"model_{seeds[0]}\"] != df_train[f\"model_{seeds[2]}\"])]\n",
    "        df_discrepencies_test = df_test[(df_test[f\"model_{seeds[0]}\"] != df_test[f\"model_{seeds[1]}\"]) | (df_test[f\"model_{seeds[0]}\"] != df_test[f\"model_{seeds[2]}\"])]\n",
    "    else:\n",
    "        print(f\"This framework does not support {len(seeds)} number of models\")\n",
    "    \n",
    "    print(f\"There are {len(df_discrepencies_train)} adversarial cases in training set.\")\n",
    "    print(f\"There are {len(df_discrepencies_test)} adversarial cases in testing set.\")\n",
    "    \n",
    "    df_discrepencies_train.reset_index(inplace=True)\n",
    "    df_discrepencies_test.reset_index(inplace=True)\n",
    "    \n",
    "    return df_discrepencies_train, df_discrepencies_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retraining_train_direct(models, epochs):\n",
    "#     models = []\n",
    "#     projs = []\n",
    "#     X_train_projs = []\n",
    "#     X_test_projs = []\n",
    "#     for i in range(len(seeds)):\n",
    "#         digit_vector, proj, X_train_copy, X_test_copy = HD_classifiers(seeds[i])\n",
    "#         models.append(digit_vector)\n",
    "#         projs.append(proj)\n",
    "#         X_train_projs.append(X_train_copy)\n",
    "#         X_test_projs.append(X_test_copy)\n",
    "    import sys\n",
    "    sys.stdout = open(\"test.txt\", \"w\")\n",
    "    df_discrepencies_train, df_discrepencies_test = discrepancies(models)\n",
    "    print(\"Retraining Started\")\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch + 1}: \")\n",
    "        for row in df_discrepencies_train.iterrows():\n",
    "            idx = row[1][\"index\"]\n",
    "            for i in range(len(seeds)):\n",
    "                y_false = row[1][f\"model_{seeds[i]}\"]\n",
    "                y_true = row[1][\"y\"]\n",
    "                hv = X_train_projs[i][idx]\n",
    "#                 np.random.seed(seeds[i])\n",
    "#                 proj = np.random.rand(D, IMG_LEN * IMG_LEN)\n",
    "#                 hv = get_scene(X_train[idx].reshape((1, -1)), proj)\n",
    "                models[i][y_false] -= hv\n",
    "                models[i][y_true] += hv\n",
    "        _, _ = discrepancies(models)\n",
    "    print(\"Retraining Stopped...\")\n",
    "    sys.stdout.close()\n",
    "    return models\n",
    "def retraining_test_direct():\n",
    "    return\n",
    "\n",
    "def retraining_train():\n",
    "    return\n",
    "\n",
    "def retraining_test():\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, labels_train, _, _ = load_dataset()\n",
    "# X_train, labels_train = shuffle(X_train, labels_train)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, labels_train, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = 10000 # dimensions in random space\n",
    "IMG_LEN = 28\n",
    "NUM_SAMPLES = X_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating random projection...\n",
      "(10000, 784)\n",
      "Projecting images to higher dim space...\n"
     ]
    }
   ],
   "source": [
    "# print(\"Generating random projection...\")\n",
    "# proj = np.random.rand(D, IMG_LEN * IMG_LEN)\n",
    "print(\"Generating random projection...\")\n",
    "seed = 50\n",
    "np.random.seed(seed)\n",
    "proj = np.random.rand(D, IMG_LEN * IMG_LEN)\n",
    "# proj[proj==0] = -1\n",
    "print(proj.shape)\n",
    "\n",
    "print(\"Projecting images to higher dim space...\")\n",
    "X_train_copy = get_scenes(X_train, proj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "digit_vectors = np.zeros((10, D))\n",
    "# num_count = {}\n",
    "for i in range(NUM_SAMPLES):\n",
    "#     num_count[y_train[i]] =  num_count.get(y_train[i], 0) + 1\n",
    "    digit_vectors[y_train[i]] += X_train_copy[i]\n",
    "digit_vectors = np.array(digit_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000,)\n",
      "(10000,)\n",
      "(40200, 10000)\n"
     ]
    }
   ],
   "source": [
    "idx = 10\n",
    "x1 = X_train_copy[idx]\n",
    "x2 = get_scene(X_train[idx], proj)\n",
    "print(x1.shape)\n",
    "print(x2.shape)\n",
    "print(X_train_copy.shape)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = classify(x1.reshape(1, -1), digit_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2], dtype=int64)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:\n",
      "0.8131094527363184\n"
     ]
    }
   ],
   "source": [
    "print(\"Train accuracy:\")\n",
    "predictions = classify(X_train_copy, digit_vectors)\n",
    "acc = accuracy_score(y_train[:X_train_copy.shape[0]], predictions)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28)\n",
      "[2]\n",
      "(28, 28)\n",
      "[2]\n",
      "(28, 28)\n",
      "[2]\n",
      "(28, 28)\n",
      "[2]\n"
     ]
    }
   ],
   "source": [
    "perturbations = [skew, elastic_transform, noise, brightness]\n",
    "\n",
    "for perturb in perturbations:\n",
    "    old_image = X_train[idx].reshape(28, 28)\n",
    "    new_image = perturb(old_image)\n",
    "    print(new_image.shape)\n",
    "    new_image = new_image.reshape(28*28)\n",
    "    new_image_proj = get_scene(new_image, proj).reshape(1, -1)\n",
    "    prediction = classify(new_image_proj, digit_vectors)\n",
    "    print(prediction)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'numpy.int32' object does not support item assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-b9f9e775c581>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mperturb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnoise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\OneDrive - Villanova University\\Desktop\\Desktop\\Fall_2020\\Senior_Project\\HDC\\senior-project-hdc-rahul-thapa\\perturbations_MNIST.py\u001b[0m in \u001b[0;36mnoise\u001b[1;34m(image, n)\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m         \u001b[0mimage\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'numpy.int32' object does not support item assignment"
     ]
    }
   ],
   "source": [
    "perturb.noise(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = 10000 # dimensions in random space\n",
    "IMG_LEN = 28\n",
    "NUM_SAMPLES = X_train.shape[0]\n",
    "seeds = [30, 40, 50]\n",
    "epochs = 5\n",
    "\n",
    "models = []\n",
    "projs = []\n",
    "X_train_projs = []\n",
    "X_test_projs = []\n",
    "for i in range(len(seeds)):\n",
    "    digit_vector, proj, X_train_copy, X_test_copy = HD_classifiers(seeds[i])\n",
    "    models.append(digit_vector)\n",
    "    projs.append(proj)\n",
    "    X_train_projs.append(X_train_copy)\n",
    "    X_test_projs.append(X_test_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retraining_train_direct(models, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "discrepancies(models, [30, 40, 50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "digit_vector, proj, _, _ = HD_classifiers(40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def retraining(seeds, epochs, retrain_on='train', method=\"direct\"):\n",
    "    models = []\n",
    "    projs = []\n",
    "    X_train_projs = []\n",
    "    X_test_projs = []\n",
    "    for i in range(len(seeds)):\n",
    "        digit_vector, proj, X_train_copy, X_test_copy = HD_classifiers(seeds[i])\n",
    "        models.append(digit_vector)\n",
    "        projs.append(proj)\n",
    "        X_train_projs.append(X_train_copy)\n",
    "        X_test_projs.append(X_test_copy)\n",
    "        \n",
    "    for epoch in range(epochs):\n",
    "        print(\"Retraining Started: \")\n",
    "        print(f\"Epoch {epoch+1}\")\n",
    "        results_test = []\n",
    "        results_train = []\n",
    "        for i in range(len(seeds)):\n",
    "            predictions_train = classify(X_train_projs[i], models[i])\n",
    "            predictions_test = classify(X_test_projs[i], models[i])\n",
    "            results_train.append(predictions_train)\n",
    "            results_test.append(predictions_test)\n",
    "        \n",
    "        results_train_dict = {}\n",
    "        results_test_dict = {}\n",
    "        model_names = []\n",
    "        for i in range(len(seeds)):\n",
    "            model_names.append(f\"model_{seeds[i]}\")\n",
    "            results_train_dict[f\"model_{seeds[i]}\"] = list(results_train[i])\n",
    "            results_test_dict[f\"model_{seeds[i]}\"] = list(results_test[i])\n",
    "        \n",
    "        df_train = pd.DataFrame(results_train_dict)\n",
    "        df_train[\"y\"] = y_train\n",
    "        df_test = pd.DataFrame(results_test_dict)\n",
    "        df_test[\"y\"] = y_test\n",
    "        \n",
    "        if retrain_on.lower() == \"train\":\n",
    "            for i in range(len(model_names)):\n",
    "                mask = (df_train[model_names[i]] != df_train[model_names[i+1]])\n",
    "                for j in range(i+2, len(model_names)):\n",
    "                    mask = mask + (df_train[model_names[i]] != df_train[model_names[j]])\n",
    "                break\n",
    "            df_discrepencies_train = df_train[mask]\n",
    "            df_discrepencies_train.reset_index(inplace=True)\n",
    "            \n",
    "            if method == \"direct\":\n",
    "                print(\"Retraining on training set...\")\n",
    "                for epoch in range(epochs):\n",
    "                    for row in df_discrepencies_train.iterrows():\n",
    "                        idx = row[1][\"index\"]\n",
    "                        for i in range(len(model_names)):\n",
    "                            y_false = row[1][model_names[i]]\n",
    "                            y_true = row[1][\"y\"]\n",
    "                            hv = get_scene(X_train[idx].reshape((1, -1)), projs[i])\n",
    "                            models[i][y_false] -= hv[0]\n",
    "                            models[i][y_true] += hv[0]\n",
    "                    \n",
    "                    print(f\"Epoch {epoch+1}\")\n",
    "                for i in range(len(seeds)):\n",
    "                    predictions = classify(X_train_projs[i], models[i])\n",
    "                    acc = accuracy_score(y_train[:X_train_projs[i].shape[0]], predictions)\n",
    "                    print(model_names[i] + \": \" + str(acc))\n",
    "                print(\"Retraining Stopped...\")\n",
    "                return models\n",
    "        if retrain_on.lower() == \"test\":\n",
    "            for i in range(len(model_names)):\n",
    "                mask = (df_test[model_names[i]] != df_test[model_names[i+1]])\n",
    "                for j in range(i+2, len(model_names)):\n",
    "                    mask = mask + (df_test[model_names[i]] != df_test[model_names[j]])\n",
    "            df_discrepencies_test = df_train[mask]\n",
    "            \n",
    "        if retrain_on.lower() == 'both':\n",
    "            for i in range(len(model_names)):\n",
    "                mask_test = (df_test[model_names[i]] != df_test[model_names[i+1]])\n",
    "                mask_train = (df_train[model_names[i]] != df_train[model_names[i+1]])\n",
    "                for j in range(i+2, len(model_names)):\n",
    "                    mask_test = mask_test + (df_test[model_names[i]] != df_test[model_names[j]])\n",
    "                    mask_train = mask_train + (df_train[model_names[i]] != df_train[model_names[j]])\n",
    "            df_discrepencies_test = df_train[mask_test]\n",
    "            df_discrepencies_train = df_train[mask_train]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "models = retraining([30, 40, 50], 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "len(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model_30, model_40, model_50 = models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import copy\n",
    "seeds = [30, 40, 50]\n",
    "results = []\n",
    "for seed, model in zip(seeds, models):\n",
    "    np.random.seed(seed)\n",
    "    proj = np.random.rand(D, IMG_LEN * IMG_LEN)\n",
    "    X_train_copy = get_scenes(X_train, proj)\n",
    "    predictions = classify(X_train_copy, model)\n",
    "    results.append(predictions)\n",
    "    print(\"here\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'model_30': list(results[0]),\n",
    "                   'model_40': list(results[1]),\n",
    "                   'model_50': list(results[2]),\n",
    "                   'y': y_train})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_discrepencies = df[(df[\"model_30\"] != df[\"model_40\"]) | (df[\"model_30\"] != df[\"model_50\"]) | (df[\"model_40\"] != df[\"model_50\"])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "len(df_discrepencies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "np.random.seed(40)\n",
    "proj = np.random.rand(D, IMG_LEN * IMG_LEN)\n",
    "X_train_copy = copy.deepcopy(X_train)\n",
    "X_train_copy = get_scenes(X_train_copy, proj)\n",
    "predictions = classify(X_train_copy, model_40)\n",
    "acc = accuracy_score(y_train[:X_train.shape[0]], predictions)\n",
    "print(acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
